{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48348b7a-4e41-46dc-b5e7-9ad19022a027",
   "metadata": {},
   "source": [
    "### Solve 2959 using rewriting/substitutions in equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f3b91-2c6e-4dd4-9729-19d85c04e43a",
   "metadata": {},
   "source": [
    "This notebook solves SAT for https://github.com/VeriFIT/smt-bench/blob/master/formulae/slog/slog_stranger_2959_sink.smt2 manually using algos from Noodler and by modifying the original equation system into an equivalent one with fewer equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe1d43e-911f-4b13-919a-7e2b9d82991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noodler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef5aa4f-2f70-4d5d-a5e2-e1ca276ea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../benchmarks/slog/slog_stranger_2959_sink.smt2\"\n",
    "parser = noodler.parser.SmtlibParserHackAbc(filename)\n",
    "orig = parser.parse_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec334b41-b3a0-4189-89a7-48750184ed58",
   "metadata": {},
   "source": [
    "Here is the list of equations and graph showing dependencies between variables. In the following, we rewrite the equations highlighted with the green box into one equation and try to solve it in one shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587bdc24-9b85-4185-847a-b84097bb2a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='vertical-align:text-top;display:inline-block;width:50%;'>['x_8'] = ['literal_7', 'sigmaStar_2']<br />['x_10'] = ['x_8', 'literal_9']<br />['x_12'] = ['x_10', 'sigmaStar_1']<br />['x_15'] = ['x_12', 'literal_13']<br />['x_17'] = ['x_15', 'sigmaStar_6']<br />['x_21'] = ['x_17', 'literal_19']<br />['x_24'] = ['x_21', 'literal_18']<br />['x_25'] = ['x_24', 'literal_23']<br />['x_26'] = ['literal_22', 'x_25']<br />['x_29'] = ['x_26', 'literal_27']<br />['x_31'] = ['x_29', 'x_25']<br />['x_33'] = ['literal_30', 'x_25']<br />['x_34'] = ['x_31', 'literal_32']<br />['x_36'] = ['x_33', 'literal_35']<br />['x_37'] = ['x_34', 'x_25']<br />['x_39'] = ['x_37', 'x_36']<br />['x_41'] = ['x_39', 'literal_40']</div><div style='vertical-align:text-top;display:inline-block;width:50%;'><img src=\"Dependency-graph-augmented.png\" alt=\"Drawing\" style=\"width: 300px;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = '<img src=\"Dependency-graph-augmented.png\" alt=\"Drawing\" style=\"width: 300px;\"/>'\n",
    "eq_str = \"<br />\".join([e.__str__() for e in orig.equations])\n",
    "\n",
    "noodler.utils.display_inline(eq_str, graph, per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcac4e0-b200-4f9c-8770-1a9ad0bc341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodler.sequery import MultiSEQuery\n",
    "from noodler.utils import show_automata\n",
    "from noodler import StringEquation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901e2852-207b-488b-9f17-4084cfe1a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_equations(query, substitute_ids):\n",
    "    \"\"\"\n",
    "    Remove (by substitution) equations from MultiSEQuery.\n",
    "    \n",
    "    Builds an equivalent query to ``query`` that does not contain\n",
    "    equations given by ids in ``substitute_ids``. These equations\n",
    "    must be assignments (e.g. of the form `xᵢ = y₁y₂...`). To maintain\n",
    "    equivalence, all occurences of `xᵢ` are substituted with `y₁y₂...`\n",
    "    and the constraints (if not equivalent to Σ*) are propagated to\n",
    "    constraints for the corresponding (left-side) variables.\n",
    "    \n",
    "    Correct for straightline fragment.\n",
    "    \n",
    "    TODO\n",
    "    ----\n",
    "    propagate constraints\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    MultiSEQuery equivalent to ``query`.\n",
    "    \"\"\"\n",
    "    # Check that all equations are assignments\n",
    "    # and that the corresponding constraints are Σ*\n",
    "    for eq_id in substitute_ids:\n",
    "        eq = query.equations[eq_id]\n",
    "        assert len(eq.left) == 1 # assignment\n",
    "        \n",
    "        var = eq.left[0]\n",
    "        constr = query.aut_constraints[var]\n",
    "        assert constr.num_useful_states() == 1\n",
    "        assert len(constr.final_states()) == 1\n",
    "    \n",
    "    substitute_vars = [query.equations[eq_id].left[0] for eq_id in substitute_ids]\n",
    "    \n",
    "    # Copy usable parts\n",
    "    working_eq = [noodler.StringEquation(eq.left, eq.right.copy()) for eq in query.equations]\n",
    "    res_eq = []\n",
    "    res_constr = {var : query.aut_constraints[var].copy() for var in query.aut_constraints if var not in substitute_vars}\n",
    "    \n",
    "    # Substitute\n",
    "    for eq_id in range(len(working_eq)):\n",
    "        eq = working_eq[eq_id]\n",
    "        # If not to removed, add to result\n",
    "        if eq_id not in substitute_ids:\n",
    "            res_eq.append(eq)\n",
    "            continue\n",
    "        \n",
    "        # Else substitute\n",
    "        var, right = eq.left[0], eq.right\n",
    "        for succ_i  in range(eq_id+1, len(working_eq)):\n",
    "            succ_eq = working_eq[succ_i]\n",
    "            if var not in succ_eq.right:\n",
    "                continue\n",
    "            # Else substitute `right` for var\n",
    "            new_succ_right = []\n",
    "            for v in succ_eq.right:\n",
    "                if v == var:\n",
    "                    new_succ_right.extend(right)\n",
    "                else:\n",
    "                    new_succ_right.append(v)\n",
    "            working_eq[succ_i] = StringEquation(succ_eq.left, new_succ_right)\n",
    "    \n",
    "    res = MultiSEQuery(res_eq, res_constr)\n",
    "    return res\n",
    "\n",
    "q = merge_equations(orig, range(8,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1bc56fd-0fce-4c65-93d3-4d1ca870233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringEquation: ['x_8'] = ['literal_7', 'sigmaStar_2'],\n",
       " StringEquation: ['x_10'] = ['x_8', 'literal_9'],\n",
       " StringEquation: ['x_12'] = ['x_10', 'sigmaStar_1'],\n",
       " StringEquation: ['x_15'] = ['x_12', 'literal_13'],\n",
       " StringEquation: ['x_17'] = ['x_15', 'sigmaStar_6'],\n",
       " StringEquation: ['x_21'] = ['x_17', 'literal_19'],\n",
       " StringEquation: ['x_24'] = ['x_21', 'literal_18'],\n",
       " StringEquation: ['x_25'] = ['x_24', 'literal_23'],\n",
       " StringEquation: ['x_39'] = ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25', 'literal_30', 'x_25', 'literal_35'],\n",
       " StringEquation: ['x_41'] = ['x_39', 'literal_40']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba15b6e-2053-4eac-a0c9-8b98df748cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringEquation: ['x_8'] = ['literal_7', 'sigmaStar_2'],\n",
       " StringEquation: ['x_10'] = ['x_8', 'literal_9'],\n",
       " StringEquation: ['x_12'] = ['x_10', 'sigmaStar_1'],\n",
       " StringEquation: ['x_15'] = ['x_12', 'literal_13'],\n",
       " StringEquation: ['x_17'] = ['x_15', 'sigmaStar_6'],\n",
       " StringEquation: ['x_21'] = ['x_17', 'literal_19'],\n",
       " StringEquation: ['x_24'] = ['x_21', 'literal_18'],\n",
       " StringEquation: ['x_25'] = ['x_24', 'literal_23'],\n",
       " StringEquation: ['x_26'] = ['literal_22', 'x_25'],\n",
       " StringEquation: ['x_29'] = ['x_26', 'literal_27'],\n",
       " StringEquation: ['x_31'] = ['x_29', 'x_25'],\n",
       " StringEquation: ['x_33'] = ['literal_30', 'x_25'],\n",
       " StringEquation: ['x_34'] = ['x_31', 'literal_32'],\n",
       " StringEquation: ['x_36'] = ['x_33', 'literal_35'],\n",
       " StringEquation: ['x_37'] = ['x_34', 'x_25'],\n",
       " StringEquation: ['x_39'] = ['x_37', 'x_36'],\n",
       " StringEquation: ['x_41'] = ['x_39', 'literal_40']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig.equations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef0540ff-3043-4900-b036-67a8a2a4fb31",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "machine = noodler.noodler.StraightlineNoodleMachine(q)\n",
    "machine.is_sat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fec4330-835b-4afd-b6b8-b5516134ac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine = noodler.noodler.StraightlineNoodleMachine(q)\n",
    "machine.is_sat(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e4b9b-dc97-48dd-880e-e0d6da1790ee",
   "metadata": {},
   "source": [
    "Here we investigate what takes that long in level 8. Is it the product? Noodlification? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fbcace-0218-4730-a608-da5a52438644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodler import SegAut, Aut\n",
    "from noodler.algos import eps_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53b0696-0542-4e50-9117-c42b2a70cf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringEquation: ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25', 'literal_30', 'x_25', 'literal_35'] = ['x_39']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = machine.noodlers[-2]\n",
    "query = n.query\n",
    "query.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a20322-024a-4c26-8161-ab39d571ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"136pt\" height=\"77pt\" viewBox=\"0.00 0.00 136.00 77.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 73)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-73 132,-73 132,4 -4,4\"/>\n",
       "<!-- I2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>I2</title>\n",
       "<ellipse fill=\"black\" stroke=\"black\" cx=\"0\" cy=\"-18\" rx=\"0\" ry=\"0\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M79,-36C79,-36 49,-36 49,-36 43,-36 37,-30 37,-24 37,-24 37,-12 37,-12 37,-6 43,0 49,0 49,0 79,0 79,0 85,0 91,-6 91,-12 91,-12 91,-24 91,-24 91,-30 85,-36 79,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">s0</text>\n",
       "</g>\n",
       "<!-- I2&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>I2-&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"DimGray\" d=\"M1.04,-18C1.86,-18 13.73,-18 26.87,-18\"/>\n",
       "<polygon fill=\"DimGray\" stroke=\"DimGray\" points=\"27,-21.5 37,-18 27,-14.5 27,-21.5\"/>\n",
       "</g>\n",
       "<!-- F2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>F2</title>\n",
       "<ellipse fill=\"black\" stroke=\"black\" cx=\"128\" cy=\"-18\" rx=\"0\" ry=\"0\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;F2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2-&gt;F2</title>\n",
       "<path fill=\"none\" stroke=\"DimGray\" d=\"M91.29,-18C100.25,-18 109.73,-18 116.68,-18\"/>\n",
       "<polygon fill=\"DimGray\" stroke=\"DimGray\" points=\"116.95,-21.5 126.95,-18 116.95,-14.5 116.95,-21.5\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2-&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.04,-36.15C54.82,-45.54 57.47,-54 64,-54 67.98,-54 70.52,-50.86 71.62,-46.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.12,-46.26 71.96,-36.15 68.13,-46.03 75.12,-46.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">[\\0x008-w]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine.noodlers[-2].query.constraints[\"x_25\"].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db595d4-adab-4b4a-a219-962589555ced",
   "metadata": {},
   "source": [
    "### It's not the product!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ea55b8-ef4f-4d11-b5f5-8842a2abc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.4 ms ± 340 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "left: SegAut = query.seg_aut(\"left\")\n",
    "right: Aut = query.proper_aut(\"right\")\n",
    "assert left.alphabet() == right.alphabet()\n",
    "product: SegAut = noodler.eps_preserving_product(left, right, history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211c6d11-94ed-40e4-827e-3bb5bd487748",
   "metadata": {},
   "outputs": [],
   "source": [
    "left: SegAut = query.seg_aut(\"left\")\n",
    "right: Aut = query.proper_aut(\"right\")\n",
    "assert left.alphabet() == right.alphabet()\n",
    "product: SegAut = noodler.eps_preserving_product(left, right, history=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11c0a6-fb7d-45a0-899f-fd763e44a8fb",
   "metadata": {},
   "source": [
    "### Investigate number of noodles\n",
    "We know that we do not care about what is in literals. Can we abstract somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1db99-321b-4780-a248-f17556fbb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "noodler.noodlify(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28849ddb-97cc-415d-a56f-b829fd433401",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = eps_segmentation(product)\n",
    "segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff07c9d-cc05-4d81-be8b-d1bef74753c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_c = 1\n",
    "for s in segmentation.values():\n",
    "    n_c *= len(s)\n",
    "print(n_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efdc795-252f-47e1-967c-b902d9372cc6",
   "metadata": {},
   "source": [
    "We have 5832 possible noodles, but only one is non-empty. Can we detect it somehow by a smarter algo? Also, we should be able to merge noodles that differ only in how literals are traversed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33208951-9c73-4745-a18f-a3e8dd068407",
   "metadata": {},
   "source": [
    "We are basically only interested in the possible constraints for `x_25` which are the segments `1,3,5,7`. We can see here that the last occurence of `x_25` has only one outgoing eps-transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bba50-260b-4fa5-8ac0-8129b7889caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in segmentation[6]:\n",
    "    print(product.get_state_name(product.src_of(tr)), product.get_state_name(product.dst_of(tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64206048-0fdc-4ae1-8247-32ea7cf044c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noodler.split_segment_aut(product)[7].display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf48c02-fbcf-4ebc-9e8f-e1647289462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_reachable(aut, tr, tr_from):\n",
    "    todo = [aut.dst_of(tr_from)]\n",
    "    visited = {aut.dst_of(tr_from)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f6916-5b98-4b93-ba02-618f09c1a304",
   "metadata": {},
   "source": [
    "## Noodle-DAG\n",
    "\n",
    "The idea of a noodle tree is to build a DAG whose nodes are ε-transitions (their ids) and there is an edge between tr₁ and tr₂ if and only if tr₂ is reachable from tr₁ with only non-ε transitions. That is, the transition are on the frontier of one segment (one at the beginning and one at the end).\n",
    "\n",
    "### Intended use\n",
    "The noodle DAG can be used to choose only viable noodles for further investigation.\n",
    "\n",
    "### Further suggestions\n",
    "\n",
    "#### Automata on edges\n",
    "The edges ofn the noodle DAG can also contain the corresponding sub-automaton (or its equivalent variant). This can be used to the following.\n",
    " 1. Directly build noodles from the noodle-DAG (but the noodles would not be needed any more).\n",
    " 2. Make some kind of unification common to several noodles.\n",
    " 3. Unify/merge noodles for one segment that 1) end in the same state of product, or put easier in the same transition, and 2) describe the same language (is this needed? not always). See the example here where we have 8 out of 9 noodles that end in the same state.\n",
    " 7337\n",
    " \n",
    " 4. ... ?\n",
    "\n",
    "#### Use backward edges as well\n",
    "This might be useful for the unification mentioned above.\n",
    "\n",
    "### Ideas\n",
    "#### Approximation based on noodle-tree shape\n",
    "\n",
    "The following works as an over-approximation or a quick way to detect unsat/kill several noodles quickly. The idea is similar to taking the whole segments instead of enumerating noodles. Here we want to merge several noodles that \"meet\" in one ε-transition even if the languages of the mini-noodles in one segment don't agree. As this is only an approximation, we might need to investigate the individual noodles one by one in case of SAT (to certify SAT).\n",
    "\n",
    "#### Accept all mini-noodles\n",
    "Mini-noodles that accept Σ* are easy to detect. We might want to treat them in a special way as in this case, we don't really care what is there. Do they appear at all? I don't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f17a60-80ca-4faa-84ae-c4ca5aff9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "noodler.split_segment_aut(product)[2].display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6920a-1fa4-4124-9c7f-b8a1b4ed24d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e178de1-fe9b-42fb-ba06-7cb81943cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32 s ± 198 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "machine = noodler.noodler.StraightlineNoodleMachine(orig)\n",
    "machine.is_sat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb687010-8659-4402-b2ea-fc7e8869e215",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "machine = noodler.noodler.StraightlineNoodleMachine(orig)\n",
    "machine.is_sat(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19adfcec-ffbe-4ca6-a4ef-69eda8b8c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = merge_equations(orig, [8,9,10,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6abe250-86d1-478a-af84-8dd3ccc2af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.54 s ± 596 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "machine = noodler.noodler.StraightlineNoodleMachine(q2)\n",
    "machine.is_sat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7e731d2-f99f-4441-aa2f-55f029b8c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====EQUATIONS====\n",
      "0: ['x_8'] = ['literal_7', 'sigmaStar_2']\n",
      "1: ['x_10'] = ['x_8', 'literal_9']\n",
      "2: ['x_12'] = ['x_10', 'sigmaStar_1']\n",
      "3: ['x_15'] = ['x_12', 'literal_13']\n",
      "4: ['x_17'] = ['x_15', 'sigmaStar_6']\n",
      "5: ['x_21'] = ['x_17', 'literal_19']\n",
      "6: ['x_24'] = ['x_21', 'literal_18']\n",
      "7: ['x_25'] = ['x_24', 'literal_23']\n",
      "8: ['x_33'] = ['literal_30', 'x_25']\n",
      "9: ['x_36'] = ['x_33', 'literal_35']\n",
      "10: ['x_37'] = ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25']\n",
      "11: ['x_39'] = ['x_37', 'x_36']\n",
      "12: ['x_41'] = ['x_39', 'literal_40']\n",
      "====Constraints` sizes====\n",
      "x_41: 9 states, 1 final\n",
      "literal_7: 98 states, 1 final\n",
      "literal_9: 24 states, 1 final\n",
      "literal_13: 41 states, 1 final\n",
      "literal_19: 35 states, 1 final\n",
      "literal_18: 13 states, 1 final\n",
      "literal_23: 78 states, 1 final\n",
      "literal_22: 100 states, 1 final\n",
      "literal_27: 16 states, 1 final\n",
      "literal_30: 14 states, 1 final\n",
      "literal_32: 10 states, 1 final\n",
      "literal_35: 50 states, 1 final\n",
      "literal_40: 16 states, 1 final\n",
      "x_15: 1 states, 1 final\n",
      "x_24: 1 states, 1 final\n",
      "x_33: 1 states, 1 final\n",
      "x_37: 1 states, 1 final\n",
      "x_12: 1 states, 1 final\n",
      "x_8: 1 states, 1 final\n",
      "x_17: 1 states, 1 final\n",
      "x_36: 1 states, 1 final\n",
      "x_21: 1 states, 1 final\n",
      "sigmaStar_6: 1 states, 1 final\n",
      "sigmaStar_2: 1 states, 1 final\n",
      "sigmaStar_1: 1 states, 1 final\n",
      "x_10: 1 states, 1 final\n",
      "x_39: 1 states, 1 final\n",
      "x_25: 1 states, 1 final\n",
      "====RUN====\n",
      "[]\n",
      "12 ['x_39', 'literal_40'] = ['x_41']\n",
      "1 noodles explored; lvl 12; noodle: 1/1\n",
      "[1]\n",
      "11 ['x_37', 'x_36'] = ['x_39']\n",
      "2 noodles explored; lvl 11; noodle: 1/9\n",
      "[9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "3 noodles explored; lvl 10; noodle: 1/1\n",
      "[1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "4 noodles explored; lvl 9; noodle: 1/1\n",
      "[1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "5 noodles explored; lvl 11; noodle: 2/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "6 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "7 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "8 noodles explored; lvl 11; noodle: 3/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "9 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "10 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "11 noodles explored; lvl 11; noodle: 4/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "12 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "13 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "14 noodles explored; lvl 11; noodle: 5/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "15 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "16 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "17 noodles explored; lvl 11; noodle: 6/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "18 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "19 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "20 noodles explored; lvl 11; noodle: 7/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "21 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "22 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "23 noodles explored; lvl 11; noodle: 8/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "24 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "25 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "26 noodles explored; lvl 11; noodle: 9/9\n",
      "[0, 1, 1, 9, 1]\n",
      "10 ['literal_22', 'x_25', 'literal_27', 'x_25', 'literal_32', 'x_25'] = ['x_37']\n",
      "27 noodles explored; lvl 10; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "9 ['x_33', 'literal_35'] = ['x_36']\n",
      "28 noodles explored; lvl 9; noodle: 1/1\n",
      "[0, 1, 1, 9, 1]\n",
      "8 ['literal_30', 'x_25'] = ['x_33']\n",
      "29 noodles explored; lvl 8; noodle: 1/1\n",
      "[1, 1, 1, 9, 1]\n",
      "7 ['x_24', 'literal_23'] = ['x_25']\n",
      "30 noodles explored; lvl 7; noodle: 1/1\n",
      "[1, 1, 1, 1, 9, 1]\n",
      "6 ['x_21', 'literal_18'] = ['x_24']\n",
      "31 noodles explored; lvl 6; noodle: 1/1\n",
      "[1, 1, 1, 1, 1, 9, 1]\n",
      "5 ['x_17', 'literal_19'] = ['x_21']\n",
      "32 noodles explored; lvl 5; noodle: 1/1\n",
      "[1, 1, 1, 1, 1, 1, 9, 1]\n",
      "4 ['x_15', 'sigmaStar_6'] = ['x_17']\n",
      "33 noodles explored; lvl 4; noodle: 1/9\n",
      "[9, 1, 1, 1, 1, 1, 1, 9, 1]\n",
      "3 ['x_12', 'literal_13'] = ['x_15']\n",
      "34 noodles explored; lvl 3; noodle: 1/8\n",
      "[8, 9, 1, 1, 1, 1, 1, 1, 9, 1]\n",
      "2 ['x_10', 'sigmaStar_1'] = ['x_12']\n",
      "35 noodles explored; lvl 2; noodle: 1/8\n",
      "[8, 8, 9, 1, 1, 1, 1, 1, 1, 9, 1]\n",
      "1 ['x_8', 'literal_9'] = ['x_10']\n",
      "36 noodles explored; lvl 1; noodle: 1/8\n",
      "[8, 8, 8, 9, 1, 1, 1, 1, 1, 1, 9, 1]\n",
      "0 ['literal_7', 'sigmaStar_2'] = ['x_8']\n",
      "37 noodles explored; lvl 0; noodle: 1/1\n",
      "[1, 8, 8, 8, 9, 1, 1, 1, 1, 1, 1, 9, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine = noodler.noodler.StraightlineNoodleMachine(q2)\n",
    "machine.is_sat(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22d726-e9a4-4270-b6ea-cf664f323576",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* [ ] In queries, allow equation to have empty constraint which would be equivalent to Σ*. Introduce alphabet.\n",
    "* [ ] Functions for modification left/right in equations that modify also the switched counterpart."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
